# mk-monitor · Plataforma SaaS multi-tenant de monitoreo y análisis inteligente de redes MikroTik

Descripción corta
mk-monitor es una plataforma comercial (SaaS) multi-tenant para monitoreo, diagnóstico y operación de redes basadas en routers MikroTik, con análisis asistido por IA, límites por plan y una UI tipo NOC moderna. Está pensada para venderse como producto (no solo un script), con control de suscripción, aislamiento de datos por cliente y métricas de SLA.

Objetivos
- Entregar un producto vendible y seguro para monitorear routers MikroTik.
- Analizar logs con IA para generar alertas accionables (qué pasó y qué hacer).
- Proveer una experiencia NOC: semáforo de salud por equipo, lista de alertas priorizadas, flujo operativo.
- Controlar límites por plan y estado comercial (activo/suspendido) con upsell.
- Exponer métricas de SLA ejecutivas.

Planes comerciales
- BASICMAAT: hasta 5 equipos — $9.99
- INTERMAAT: hasta 15 equipos — $24.99
- PROMAAT: equipos ilimitados — $44.99

Reglas de negocio de suscripción
- Respetar límite de equipos según plan activo.
- Si intenta exceder el límite → respuesta 402 y flujo de upsell (modal en frontend).
- Si el tenant está suspendido por pagos → permitir login pero bloquear acciones críticas; mostrar banner en UI.

Arquitectura (visión general)
- Frontend: React + Vite (UI estilo NOC, dark/light mode).
- Backend: Flask (Python 3.11+), SQLAlchemy, Alembic (TODO migraciones), CORS, JWT.
- Base de datos: PostgreSQL (gestión con pgAdmin).
- Infra local: docker-compose (postgres, pgadmin, backend, frontend), variables en infra/.env.
- Capa IA: servicio interno (ai_analysis_service) que analiza logs Mikrotik y propone alertas con acción recomendada.
- Seguridad:
  - Aislamiento por tenant_id en todas las consultas.
  - Hash de contraseñas con bcrypt.
  - JWT con expiración obligatoria (HS256).
  - Cifrado simétrico en reposo (Fernet) para credenciales de los routers.
  - Control rudimentario de fuerza bruta en login (en memoria; en prod usar Redis).

Flujo principal de valor
1) Cliente inicia sesión (JWT).
2) Ve dashboard: salud de equipos (verde/amarillo/rojo), alertas críticas primero, recomendaciones accionables.
3) Equipo NOC opera alertas como tickets: Pendiente → En curso → Resuelta, con comentarios y trazabilidad.
4) Sistema calcula y expone SLA (p. ej., tiempo promedio de resolución de severas este mes).
5) Export de histórico (CSV; PDF pendiente).

Modelo de datos (PostgreSQL)
- Tenant (tenants)
  - id (PK), name, plan ("BASICMAAT" | "INTERMAAT" | "PROMAAT"), status_pago ("activo"|"suspendido"), created_at.
- Subscription (subscriptions)
  - id (PK), tenant_id (FK), plan_name, max_devices (int), activo_hasta (datetime), created_at.
  - Uso: histórico de cambios de plan; plan vigente = fila más reciente con activo_hasta >= now().
- User (users)
  - id (PK), tenant_id (FK), email (único dentro del tenant), password_hash, role ("admin"|"noc"), created_at.
  - Sugerido: UNIQUE(tenant_id, email). Hash con bcrypt.
- Device (devices)
  - id (PK), tenant_id (FK), name, ip_address, port, username_encrypted, password_encrypted, firmware_version?, location?, wan_type?, created_at.
  - Nota: username/password cifrados con cryptography.Fernet usando ENCRYPTION_KEY (entorno). Nunca exponerlos.
- Alert (alerts)
  - id (PK), tenant_id (FK), device_id (FK), estado ("Aviso"|"Alerta Menor"|"Alerta Severa"|"Alerta Crítica"), titulo, descripcion, accion_recomendada, status_operativo ("Pendiente"|"En curso"|"Resuelta"), comentario_ultimo?, created_at, updated_at.
- AlertStatusHistory (alert_status_history)
  - id (PK), alert_id (FK), previous_status_operativo, new_status_operativo, changed_by_user_id (FK), changed_at.
  - Para trazabilidad y SLA.
- LogEntry (logs)
  - id (PK), tenant_id (FK), device_id (FK), raw_log (texto largo), log_level?, timestamp_equipo (datetime del evento en router), created_at.
  - Índices: (tenant_id, device_id, timestamp_equipo) para consultas por rango.

Notas de modelado y performance
- Usar DateTime(timezone=True), normalizar a UTC; documentar interpretación de zonas horarias.
- Índices recomendados:
  - logs: (tenant_id, device_id, timestamp_equipo), (tenant_id, created_at).
  - alerts: (tenant_id, device_id, status_operativo), (tenant_id, estado, created_at).
  - users: UNIQUE(tenant_id, email).
  - subscriptions: (tenant_id, activo_hasta DESC).
- Considerar RLS en Postgres como defensa adicional (TODO).

Autenticación y control de acceso
- Passwords: bcrypt.
- JWT:
  - Payload: sub (user_id), tenant_id, role, exp.
  - Emisión en login; expiración obligatoria; HS256.
- Decorator @require_auth(role=None):
  - Lee Authorization Bearer, decodifica JWT, setea g.user_id, g.tenant_id, g.role.
  - Valida rol si se requiere (p. ej. admin).
- Rate limiting de login:
  - Contador en memoria por IP/email; 429 tras múltiples fallos; reset en éxito. En prod: Redis/rate limiter.
- CORS: abierto en dev; restringir orígenes en prod.
- Sanitización: nunca exponer username_encrypted/password_encrypted; evitar campos internos innecesarios en respuestas.

Lógica de negocio clave
- Límite de dispositivos por plan:
  - BASICMAAT = 5, INTERMAAT = 15, PROMAAT = ilimitado (None).
  - En POST /api/devices: si supera límite → 402 { upsell: true, message, required_plan_hint }.
- Suspensión comercial:
  - Tenant.status_pago "suspendido": permitir login y lectura; bloquear acciones críticas. Frontend muestra banner/badge visible.
- Health status por equipo (semáforo):
  - rojo: alerta activa (no resuelta) con estado "Alerta Severa"/"Alerta Crítica".
  - amarillo: alerta activa (no resuelta) con estado "Alerta Menor".
  - verde: en otro caso.
- SLA:
  - Métrica principal: tiempo_promedio_resolucion_severa_min en el mes actual.
  - Calculado con la creación de la alerta y la primera transición a "Resuelta" en AlertStatusHistory.

Servicios backend (services/)
- subscription_service.py
  - get_current_subscription(tenant_id) → { plan_name, max_devices, status_pago, devices_registrados }.
  - can_add_device(tenant_id) → bool + razón de upsell.
- device_service.py
  - list_devices_for_tenant(tenant_id).
  - create_device(tenant_id, payload):
    - Verifica can_add_device; si no, lanza DeviceLimitReached.
    - Cifra username/password con Fernet (encrypt_secret/decrypt_secret).
    - Retorna el device creado sin credenciales.
- alert_service.py
  - list_alerts(tenant_id, filtros: estado, device_id, fecha_inicio, fecha_fin, status_operativo).
  - update_alert_status(alert_id, user_id, tenant_id, nuevo_status, comentario):
    - Valida tenant; actualiza status_operativo/comentario_ultimo/updated_at.
    - Inserta AlertStatusHistory con previous/new y changed_by_user_id, changed_at (UTC).
  - compute_device_health(tenant_id, device_id) → "verde"/"amarillo"/"rojo".
- sla_service.py
  - get_sla_metrics(tenant_id) → { tiempo_promedio_resolucion_severa_min } (mes actual).
- monitoring_service.py (stub)
  - get_router_logs(device) → lista de logs crudos (TODO integrar ros_api/RouterOS).
  - analyze_and_generate_alerts(device):
    - Trae logs, llama ai_analysis_service.analyze_logs, inserta LogEntry y Alert cuando corresponda (TODO detalles de conexión/errores).
- ai_analysis_service.py
  - analyze_logs(log_list) → lista de dicts normalizados { estado, titulo, descripcion, accion_recomendada }.
  - Heurísticas MVP:
    - "login failed" → posible ataque de fuerza bruta.
    - "pppoe reconnect" repetido → inestabilidad WAN severa.
  - Comentario: en futuro integrar LLM (DeepSeek u otro).

Rutas / API (routes/)
- Auth (auth_routes.py)
  - POST /api/auth/login → { token, role, tenant_status }.
  - Rate limit rudimentario (429 en múltiples fallos).
- Devices (device_routes.py)
  - GET /api/devices → devices del tenant + health_status calculado.
  - POST /api/devices (admin):
    - Crea device; si límite excedido → 402 upsell; en éxito → 201.
- Alerts (alert_routes.py)
  - GET /api/alerts → filtros: estado, device_id, fecha_inicio, fecha_fin, status_operativo (siempre por tenant_id).
- NOC (noc_routes.py)
  - PATCH /api/alerts/:id/status → body { status_operativo, comentario } → update_alert_status.
- Logs (log_routes.py)
  - GET /api/devices/:device_id/logs → query: limit (5/10/20), fecha_inicio, fecha_fin.
  - export=csv → text/csv con columnas: timestamp_equipo, device_id, raw_log.
  - export=pdf → 501 JSON { "todo": "PDF export pendiente" } (luego ReportLab/WeasyPrint).
- Subscription (subscription_routes.py)
  - GET /api/subscription/status → { plan, max_devices, devices_registrados, status_pago, suspended? }.
- Health (health_routes.py)
  - GET /api/health/devices → [{ device_id, name, health_status }].
- SLA (sla_routes.py)
  - GET /api/sla/metrics → { tiempo_promedio_resolucion_severa_min }.

Frontend (React + Vite)
- Contextos
  - AuthContext.jsx: token JWT, role, tenantStatus; login() → /api/auth/login; logout(); persistencia en localStorage.
  - ThemeContext.jsx: dark/light toggle, persistencia en localStorage, aplica clase al body.
- API
  - client.js: axios con baseURL http://localhost:5000/api; header Authorization Bearer <token> (interceptor/TODO).
  - authApi.js, deviceApi.js (maneja 402 upsell), alertApi.js, subscriptionApi.js.
- Componentes
  - Layout: Sidebar (navegación: Dashboard, Equipos, Alertas, NOC, Suscripción), Header (tenant, logout, ThemeToggle, banner suspendido), ThemeToggle.
  - StatusBadge (colores por estado).
  - DeviceHealthIndicator (semáforo verde/amarillo/rojo).
  - AlertCard (titulo, estado, descripcion, accion_recomendada, status_operativo, comentario_ultimo, timestamp; botón “Marcar En curso/Resuelta” → TODO flujo NOC).
  - UpsellModal (texto comercial y CTA).
- Pages
  - LoginPage (form email/password → AuthContext.login()).
  - DashboardPage (KPIs: total alertas, críticas, salud global; TODO integra /api/alerts y /api/health/devices).
  - DevicesPage (lista equipos + semáforo; [+ Agregar] → createDevice; si 402 → UpsellModal).
  - DeviceDetailPage (info equipo + alertas del equipo + logs con selector 5/10/20 y filtro por rango).
  - AlertsPage (lista/tabla con filtros: fechas, estado, equipo, status_operativo).
  - SubscriptionPage (plan actual, usados/límite, estado de pago, CTA “Actualizar plan”).
  - NocActivityPage (alertas “En curso” y quién las atiende).
- Rutas en App.jsx
  - "/", "/login", "/devices", "/devices/:deviceId", "/alerts", "/subscription", "/noc".
  - Si no hay token → redirigir a /login. TODO: protección por roles.

UX / UI
- Estilo sobrio tipo NOC/macOS (dark por defecto; toggle a light).
- Semáforo visible en lista de equipos y detalle.
- Alertas agrupables y con acción recomendada (accion_recomendada).
- Banner rojo si tenant suspendido.

Histórico, tendencias y export
- Logs almacenados por device/tenant con timestamp_equipo.
- Consulta por rango de fechas/horas (p. ej., “ayer a las 3AM”).
- Paginación/limit 5/10/20.
- Export CSV listo; export PDF placeholder (501) con TODO de implementación.

Seguridad (detalle)
- Hash de contraseñas con bcrypt (salt work factor recomendado ~12).
- JWT con expiración y validación de firma; manejo de errores (exp, inválido).
- Cifrado en reposo de credenciales de routers con Fernet; validar ENCRYPTION_KEY (debe ser base64 urlsafe de 32 bytes); nota de rotación.
- Aislamiento estricto por tenant_id en todas las consultas (services y rutas). Considerar RLS (TODO).
- Sanitización de respuestas: no exponer secretos ni campos internos.
- Rate limiting rudimentario en login (en memoria). En producción: Redis / rate limiter.

Infraestructura
- docker-compose.yml (infra/)
  - Servicios:
    - postgres (volumen persistente).
    - pgadmin (UI de BD).
    - backend (build ../backend, puerto 5000; TODO Dockerfile).
    - frontend (build ../frontend, puerto 5173; TODO Dockerfile).
  - Red compartida: mknet.
  - depends_on apropiado y comentarios por servicio.
- .env.example (infra/)
  - POSTGRES_HOST=postgres
  - POSTGRES_DB=mkmonitor
  - POSTGRES_USER=mkadmin
  - POSTGRES_PASSWORD=mkpassword
  - JWT_SECRET=changeme_jwt_secret
  - ENCRYPTION_KEY=changeme_32bytes_base64
  - APP_ENV=dev
  - Nota: “Copia este archivo a .env y personaliza los valores”.
- .gitignore (raíz)
  - /infra/.env, /backend/__pycache__/, /backend/*.pyc, /backend/.venv/, /frontend/node_modules/, /frontend/dist/, *.log, *.sqlite, __pycache__/, patrones para llaves/secretos.

Prototipo previo (contexto histórico)
- app.py (Flask básico), conectai.py (ros_api + DeepSeek), index.html (Bootstrap NOC).
- El prototipo inspiró:
  - Heurísticas de IA (“login failed”, “pppoe reconnect”).
  - UI NOC con severidades.
- La plataforma actual formaliza multi-tenant, seguridad, planes, SLA y frontend React + backend Flask modular.

Operación y SLA
- Trazabilidad: AlertStatusHistory guarda quién cambió estado y cuándo (UTC).
- KPI: tiempo_promedio_resolucion_severa_min en el mes.
- Exposición: GET /api/sla/metrics.

Pruebas, migraciones y calidad (TODO)
- Alembic: crear migraciones iniciales.
- Tests automatizados (pytest):
  - Auth (hash/JWT/exp).
  - Aislamiento por tenant (ningún cross-tenant leak).
  - Límite de plan y upsell (402).
  - SLA metrics.
- Lint/format:
  - Backend: black, flake8, isort.
  - Frontend: eslint, prettier.
- E2E básicos (login → crear device → upsell).
- Dockerfiles backend/frontend y pipeline CI/CD.
- Observabilidad: logging estructurado (JSON), métricas, healthchecks.
- Retención/archivado de logs y compliance (GDPR/LOPD si aplica).
- Ingesta de logs a escala (push Syslog vs pull ros_api) y worker programado (Celery/RQ + Redis) (TODO).

Riesgos y mitigación (resumen)
- Volumen de logs alto → índices, retención, posible syslog listener y colas.
- Gestión de claves (ENCRYPTION_KEY/JWT_SECRET) → validación al boot, rotación, secret manager en prod.
- Fugas de datos multi-tenant → RLS + tests de aislamiento + revisiones.
- Validación de entradas → introducir esquemas (Marshmallow/Pydantic).
- Latencia/coste de IA → caché/colas y análisis asíncrono; selección de modelo/endpoint.

Roadmap por etapas (resumen)
- ETAPA 1: Estructura del repo (backend, frontend, infra) con comentarios.
- ETAPA 2: Backend Flask base, app factory, modelos, auth utils, rutas esqueleto, README.
- ETAPA 3: Frontend React base, routing, contextos, componentes NOC, Upsell.
- ETAPA 4: Reglas negocio (planes, health, SLA, servicios/rutas).
- ETAPA 5: Seguridad extra, auditoría, export CSV/PDF placeholder, .gitignore, docker-compose detallado.
- ETAPA 6: Documentación operativa (README raíz/backend/infra), TODO.md de pendientes críticos.

Definición de “hecho” (DoD) por MVP
- Login funcional con JWT, roles y banner de suspensión.
- Registro/lista de equipos con cifrado de credenciales y límite de plan con upsell.
- Ingesta mínima de logs (stub) y generación de alertas por heurística IA.
- Semáforo de salud y vistas de alertas (filtros básicos).
- Export CSV de logs y SLA KPI disponible.
- Frontend navegable (rutas/contextos) y compila con npm run dev.
- Aislamiento por tenant y sanitización de respuestas.

Conclusión
mk-monitor consolida prácticas de producto SaaS multi-tenant, seguridad, análisis con IA y experiencia NOC para redes MikroTik. El diseño está preparado para escalar a integración real con RouterOS y modelos IA avanzados, observabilidad y CI/CD, manteniendo la prioridad en seguridad, aislamiento y valor operativo (alertas accionables, SLA).